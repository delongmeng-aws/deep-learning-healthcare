{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GNN\n",
    "\n",
    "## Overview\n",
    "\n",
    "In this project, we will try the Graph Neural Network (GNN).\n",
    "\n",
    "We will use [PyTorch Geometric](https://pytorch-geometric.readthedocs.io/en/latest/index.html), which is a geometric deep learning extension library for PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed\n",
    "seed = 24\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"lib/data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Graph\n",
    "\n",
    "First, let us learn the fundamental concepts of PyTorch Geometric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A graph is used to model pairwise relations (edges) between objects (nodes).\n",
    "A single graph in PyTorch Geometric is described by an instance of `torch_geometric.data.Data`, which holds the following attributes by default:\n",
    "\n",
    "- `data.x`: Node feature matrix with shape `[num_nodes, num_node_features]`\n",
    "- `data.edge_index`: Graph connectivity in COO format with shape `[2, num_edges]` and type `torch.long`\n",
    "- `data.edge_attr`: Edge feature matrix with shape `[num_edges, num_edge_features]`\n",
    "- `data.y`: Target to train against (may have arbitrary shape), *e.g.*, node-level targets of shape `[num_nodes, *]` or graph-level targets of shape `[1, *]`\n",
    "- `data.pos`: Node position matrix with shape `[num_nodes, num_dimensions]`\n",
    "\n",
    "Note that none of these attributes is required.\n",
    "\n",
    "We show a simple example of an unweighted and undirected graph with three nodes and four edges. Each node contains exactly one feature:\n",
    "\n",
    "<img width=\"500\" src=\"img/graph-1.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[3, 1], edge_index=[2, 4])\n",
      "num_nodes: 3\n",
      "num_edges: 4\n",
      "num_node_features: 1\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import Data\n",
    "\n",
    "edge_index = torch.tensor([[0, 1, 1, 2],\n",
    "                           [1, 0, 2, 1]], dtype=torch.long)\n",
    "x = torch.tensor([[-1], [0], [1]], dtype=torch.float)\n",
    "\n",
    "data = Data(x=x, edge_index=edge_index)\n",
    "print(data)\n",
    "print(\"num_nodes:\", data.num_nodes)\n",
    "print(\"num_edges:\", data.num_edges)\n",
    "print(\"num_node_features:\", data.num_node_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that although the graph has only two edges, we need to define four index tuples to account for both directions of a edge.\n",
    "\n",
    "Now, create a `torch_geometric.data.Data` instance for the following graph.\n",
    "\n",
    "<img width=\"250\" src=\"img/graph-2.png\">\n",
    "\n",
    "Assign the graph-level target $1$ to the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a `torch_geometric.data.Data` instance for the graph above. Set the graph-level target to 1.\n",
    "edge_index = torch.tensor([[0, 0, 1, 2],\n",
    "                           [1, 2, 3, 1]], dtype=torch.long)\n",
    "data = Data(edge_index=edge_index, num_nodes=4, y=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Dataset\n",
    "\n",
    "For this project, we will use the [MUTAG dataset](http://networkrepository.com/Mutag.php). Each graph in the dataset represents a chemical compound and graph labels represent their mutagenic effect on a specific gram negative bacterium. The dataset includes 188 graphs. Graph nodes have 7 labels and each graph is labelled as belonging to 1 of 2 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len: 188\n",
      "num_classes: 2\n",
      "num_node_features: 7\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import TUDataset\n",
    "\n",
    "dataset = TUDataset(root=DATA_PATH, name='MUTAG')\n",
    "print(\"len:\", len(dataset))\n",
    "print(\"num_classes:\", dataset.num_classes)\n",
    "print(\"num_node_features:\", dataset.num_node_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us take one graph as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 17\n",
      "Number of edges: 38\n",
      "Number of features: 7\n",
      "Average node degree: 2.24\n",
      "Contains isolated nodes: False\n",
      "Contains self-loops: False\n",
      "Is undirected: True\n"
     ]
    }
   ],
   "source": [
    "data = dataset[0]\n",
    "print(f'Number of nodes: {data.num_nodes}')\n",
    "print(f'Number of edges: {data.num_edges}')\n",
    "print(f'Number of features: {data.num_node_features}')\n",
    "print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
    "print(f'Contains isolated nodes: {data.contains_isolated_nodes()}')\n",
    "print(f'Contains self-loops: {data.contains_self_loops()}')\n",
    "print(f'Is undirected: {data.is_undirected()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the first graph in the dataset contains 17 nodes, each one having 7 features. There are 38/2 = 19 undirected edges and the graph is assigned to exactly one class. In addition, the data object is holding exactly one graph-level target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_stat(dataset):\n",
    "    \"\"\"\n",
    "    Calculate the statistics of the ENZYMES dataset.\n",
    "    \n",
    "    Outputs:\n",
    "        min_num_nodes: min number of nodes\n",
    "        max_num_nodes: max number of nodes\n",
    "        mean_num_nodes: average number of nodes\n",
    "        min_num_edges: min number of edges\n",
    "        max_num_edges: max number of edges\n",
    "        mean_num_edges: average number of edges\n",
    "    \"\"\"\n",
    "    num_nodes_array = []\n",
    "    num_edges_array = []\n",
    "    for g in dataset:\n",
    "        num_nodes_array.append(g.num_nodes)\n",
    "        num_edges_array.append(g.num_edges)\n",
    "\n",
    "    num_nodes_np = np.array(num_nodes_array)\n",
    "    num_edges_np = np.array(num_edges_array)\n",
    "\n",
    "    return (num_nodes_np.min(), num_nodes_np.max(), num_nodes_np.mean(),\n",
    "            num_edges_np.min(), num_edges_np.max(), num_edges_np.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural networks are usually trained in a batch-wise fashion. PyTorch Geometric achieves parallelization over a mini-batch by creating sparse block diagonal adjacency matrices (defined by `edge_index`) and concatenating feature and target matrices in the node dimension. This composition allows differing number of nodes and edges over examples in one batch:\n",
    "\n",
    "$\\begin{split}\\mathbf{A} = \\begin{bmatrix} \\mathbf{A}_1 & & \\\\ & \\ddots & \\\\ & & \\mathbf{A}_n \\end{bmatrix}, \\qquad \\mathbf{X} = \\begin{bmatrix} \\mathbf{X}_1 \\\\ \\vdots \\\\ \\mathbf{X}_n \\end{bmatrix}, \\qquad \\mathbf{Y} = \\begin{bmatrix} \\mathbf{Y}_1 \\\\ \\vdots \\\\ \\mathbf{Y}_n \\end{bmatrix}\\end{split}$\n",
    "\n",
    "Luckily, PyTorch Geometric contains its own `torch_geometric.data.DataLoader`, which already takes care of this concatenation process. Let us learn about it in an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(edge_index=[2, 1260], x=[571, 7], edge_attr=[1260, 4], y=[32], batch=[571], ptr=[33])\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "loader_iter = iter(loader)\n",
    "batch = next(loader_iter)\n",
    "print(batch)\n",
    "print(batch.num_graphs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is, each batch contains $32$ graphs whose nodes and edges are stacked into one matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us create a 80/20 train/test split, and load them into the dataloaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len train: 150\n",
      "len test: 38\n"
     ]
    }
   ],
   "source": [
    "# shuffle\n",
    "dataset = dataset.shuffle()\n",
    "# split\n",
    "split_idx = int(len(dataset) * 0.8)\n",
    "train_dataset = dataset[:split_idx]\n",
    "test_dataset = dataset[split_idx:]\n",
    "\n",
    "print(\"len train:\", len(train_dataset))\n",
    "print(\"len test:\", len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Graph Neural Network\n",
    "\n",
    "After learning about the fundamental concepts in PyTorch Geometric, let us try implement our first graph neural network.\n",
    "\n",
    "We will use a simple Graph Convolution Network (GCN) to assign each enzyme to one of the 6 EC top-level classes.\n",
    "\n",
    "For a high-level explanation on GCN, have a look at its [blog](http://tkipf.github.io/graph-convolutional-networks/) post."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first implement a GCN layer. A GCN layer is given an adjacency matrix $A\\in\\mathbb{R}^{N\\times N}$ and a node feature matrix $X\\in\\mathbb{R}^{N\\times D_{in}}$, where $N$ is the number of nodes and $D_{in}$ is the input dimension. The graph convolution network will calculate its output by:\n",
    "\n",
    "$$\n",
    "X' = \\hat{D}^{-1/2}\\hat{A}\\hat{D}^{-1/2}X\\Theta\n",
    "$$\n",
    "\n",
    "where $\\hat{A}=A+I$ denotes the adjacency matrix with self-loop, $\\hat{D}_{ii}=\\sum_{j=0}^{N-1}A_{ij}$ is its diagonal degree matrix and $\\Theta\\in\\mathbb{R}^{D_{in}\\times D_{out}}$ is the model parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class GCNConv(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(GCNConv, self).__init__()\n",
    "        self.theta = nn.Parameter(torch.FloatTensor(in_channels, out_channels))\n",
    "        # Initialize the parameters.\n",
    "        stdv = 1. / math.sqrt(out_channels)\n",
    "        self.theta.data.uniform_(-stdv, stdv)\n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        # Generate the adjacency matrix with self-loop \\hat{A} using edge_index\n",
    "        A_hat = torch.eye(x.shape[0])\n",
    "        for i in np.arange(start=0, stop=edge_index.shape[1]):\n",
    "            node_from = edge_index[0, i].item()\n",
    "            node_to = edge_index[1, i].item()\n",
    "            A_hat[node_from, node_to] += 1\n",
    "        \n",
    "        # Calculate the diagonal degree matrix \\hat{D}\n",
    "        D_diag = 1/A_hat.sum(dim=1).sqrt()\n",
    "        D_hat_normalized = torch.diag(input=D_diag)\n",
    "\n",
    "        # Calculate the output X' with torch.mm using the equation above\n",
    "        ret = D_hat_normalized @ A_hat @ D_hat_normalized @ x @ self.theta\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img width=\"500\" src=\"img/graph-3.png\">\n",
    "\n",
    "The GCN will have the following steps:\n",
    "\n",
    "- Embed each node by performing multiple rounds of message passing\n",
    "- Aggregate node embeddings into a unified graph embedding (readout layer)\n",
    "- Train a final classifier on the graph embedding\n",
    "\n",
    "\n",
    "There exists multiple readout layers in literature, but the most common one is to simply take the average of node embeddings:\n",
    "\n",
    "$$\n",
    "\\mathbf{x}_{\\mathcal{G}} = \\frac{1}{|\\mathcal{V}|} \\sum_{v \\in \\mathcal{V}} \\mathcal{x}^{(L)}_v\n",
    "$$\n",
    "\n",
    "PyTorch Geometric provides this functionality via `torch_geometric.nn.global_mean_pool`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GCN(\n",
       "  (conv1): GCNConv()\n",
       "  (conv2): GCNConv()\n",
       "  (conv3): GCNConv()\n",
       "  (relu): ReLU()\n",
       "  (drop): Dropout(p=0.5, inplace=False)\n",
       "  (linear): Linear(in_features=64, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GCN, self).__init__()\n",
    "\n",
    "        self.conv1 = GCNConv(in_channels=node_features, out_channels=num_channels)\n",
    "        self.conv2 = GCNConv(in_channels=num_channels, out_channels=num_channels)\n",
    "        self.conv3 = GCNConv(in_channels=num_channels, out_channels=num_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.drop = nn.Dropout()\n",
    "        self.linear = nn.Linear(in_features=num_channels, out_features=2)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        \"\"\" \n",
    "        Arguments:\n",
    "            x: [num_nodes, 7], node features\n",
    "            edge_index: [2, num_edges], edges\n",
    "            batch: [num_nodes], batch assignment vector which maps each node to its \n",
    "                   respective graph in the batch\n",
    "\n",
    "        Outputs:\n",
    "            probs: probabilities of shape (batch_size, 2)\n",
    "        \"\"\"\n",
    "\n",
    "        conv1_out = self.conv1(x=x, edge_index=edge_index)\n",
    "        relu1_out = self.relu(conv1_out)\n",
    "        conv2_out = self.conv2(x=relu1_out, edge_index=edge_index)\n",
    "        relu2_out = self.relu(conv2_out)\n",
    "        conv3_out = self.conv3(x=relu2_out, edge_index=edge_index)\n",
    "\n",
    "        graph_emb = global_mean_pool(x=conv3_out, batch=batch)\n",
    "        graph_drop = self.drop(graph_emb)\n",
    "        graph_linear = self.linear(graph_drop)\n",
    "        probs = graph_linear.softmax(dim=-1)\n",
    "        return probs\n",
    "        \n",
    "GCN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Training and Inferencing\n",
    "\n",
    "Let us train our network for a few epochs to see how well it performs on the training as well as test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train Acc: 0.6467, Test Acc: 0.7368\n",
      "Epoch: 002, Train Acc: 0.6467, Test Acc: 0.7368\n",
      "Epoch: 003, Train Acc: 0.6467, Test Acc: 0.7368\n",
      "Epoch: 004, Train Acc: 0.6467, Test Acc: 0.7368\n",
      "Epoch: 005, Train Acc: 0.6467, Test Acc: 0.7368\n",
      "Epoch: 006, Train Acc: 0.7067, Test Acc: 0.7368\n",
      "Epoch: 007, Train Acc: 0.7400, Test Acc: 0.8158\n",
      "Epoch: 008, Train Acc: 0.7200, Test Acc: 0.8158\n",
      "Epoch: 009, Train Acc: 0.7400, Test Acc: 0.8158\n",
      "Epoch: 010, Train Acc: 0.7267, Test Acc: 0.7368\n",
      "Epoch: 011, Train Acc: 0.7400, Test Acc: 0.8158\n",
      "Epoch: 012, Train Acc: 0.7400, Test Acc: 0.8158\n",
      "Epoch: 013, Train Acc: 0.7333, Test Acc: 0.7368\n",
      "Epoch: 014, Train Acc: 0.7333, Test Acc: 0.8421\n",
      "Epoch: 015, Train Acc: 0.7400, Test Acc: 0.8158\n",
      "Epoch: 016, Train Acc: 0.7467, Test Acc: 0.7368\n",
      "Epoch: 017, Train Acc: 0.7533, Test Acc: 0.7632\n",
      "Epoch: 018, Train Acc: 0.7467, Test Acc: 0.8158\n",
      "Epoch: 019, Train Acc: 0.7533, Test Acc: 0.7895\n",
      "Epoch: 020, Train Acc: 0.7533, Test Acc: 0.7895\n",
      "Epoch: 021, Train Acc: 0.7400, Test Acc: 0.8158\n",
      "Epoch: 022, Train Acc: 0.7533, Test Acc: 0.8158\n",
      "Epoch: 023, Train Acc: 0.7600, Test Acc: 0.7632\n",
      "Epoch: 024, Train Acc: 0.7667, Test Acc: 0.7895\n",
      "Epoch: 025, Train Acc: 0.7333, Test Acc: 0.8158\n",
      "Epoch: 026, Train Acc: 0.7400, Test Acc: 0.8158\n",
      "Epoch: 027, Train Acc: 0.7400, Test Acc: 0.7895\n",
      "Epoch: 028, Train Acc: 0.7733, Test Acc: 0.7895\n",
      "Epoch: 029, Train Acc: 0.7800, Test Acc: 0.8158\n",
      "Epoch: 030, Train Acc: 0.7733, Test Acc: 0.7895\n",
      "Epoch: 031, Train Acc: 0.7733, Test Acc: 0.7895\n",
      "Epoch: 032, Train Acc: 0.7800, Test Acc: 0.8158\n",
      "Epoch: 033, Train Acc: 0.7733, Test Acc: 0.8158\n",
      "Epoch: 034, Train Acc: 0.7600, Test Acc: 0.7895\n",
      "Epoch: 035, Train Acc: 0.7333, Test Acc: 0.8158\n",
      "Epoch: 036, Train Acc: 0.7733, Test Acc: 0.8158\n",
      "Epoch: 037, Train Acc: 0.7733, Test Acc: 0.8158\n",
      "Epoch: 038, Train Acc: 0.7733, Test Acc: 0.7632\n",
      "Epoch: 039, Train Acc: 0.7867, Test Acc: 0.8158\n",
      "Epoch: 040, Train Acc: 0.7667, Test Acc: 0.7632\n",
      "Epoch: 041, Train Acc: 0.7800, Test Acc: 0.8158\n",
      "Epoch: 042, Train Acc: 0.7800, Test Acc: 0.7632\n",
      "Epoch: 043, Train Acc: 0.7800, Test Acc: 0.8158\n",
      "Epoch: 044, Train Acc: 0.7600, Test Acc: 0.7895\n",
      "Epoch: 045, Train Acc: 0.7667, Test Acc: 0.7895\n",
      "Epoch: 046, Train Acc: 0.8133, Test Acc: 0.8158\n",
      "Epoch: 047, Train Acc: 0.7667, Test Acc: 0.7632\n",
      "Epoch: 048, Train Acc: 0.7867, Test Acc: 0.8158\n",
      "Epoch: 049, Train Acc: 0.7800, Test Acc: 0.8158\n",
      "Epoch: 050, Train Acc: 0.7733, Test Acc: 0.7632\n",
      "Epoch: 051, Train Acc: 0.8133, Test Acc: 0.8158\n",
      "Epoch: 052, Train Acc: 0.7867, Test Acc: 0.7895\n",
      "Epoch: 053, Train Acc: 0.7933, Test Acc: 0.7895\n",
      "Epoch: 054, Train Acc: 0.8267, Test Acc: 0.7632\n",
      "Epoch: 055, Train Acc: 0.7400, Test Acc: 0.7368\n",
      "Epoch: 056, Train Acc: 0.8000, Test Acc: 0.8158\n",
      "Epoch: 057, Train Acc: 0.7867, Test Acc: 0.8158\n",
      "Epoch: 058, Train Acc: 0.7733, Test Acc: 0.7368\n",
      "Epoch: 059, Train Acc: 0.7800, Test Acc: 0.7895\n",
      "Epoch: 060, Train Acc: 0.8067, Test Acc: 0.7895\n",
      "Epoch: 061, Train Acc: 0.8067, Test Acc: 0.7895\n",
      "Epoch: 062, Train Acc: 0.8200, Test Acc: 0.7632\n",
      "Epoch: 063, Train Acc: 0.8067, Test Acc: 0.7632\n",
      "Epoch: 064, Train Acc: 0.8200, Test Acc: 0.8158\n",
      "Epoch: 065, Train Acc: 0.8200, Test Acc: 0.7895\n",
      "Epoch: 066, Train Acc: 0.8133, Test Acc: 0.7895\n",
      "Epoch: 067, Train Acc: 0.8200, Test Acc: 0.7632\n",
      "Epoch: 068, Train Acc: 0.8200, Test Acc: 0.7632\n",
      "Epoch: 069, Train Acc: 0.8200, Test Acc: 0.7632\n",
      "Epoch: 070, Train Acc: 0.8200, Test Acc: 0.7632\n",
      "Epoch: 071, Train Acc: 0.8133, Test Acc: 0.7895\n",
      "Epoch: 072, Train Acc: 0.8133, Test Acc: 0.7895\n",
      "Epoch: 073, Train Acc: 0.8000, Test Acc: 0.7895\n",
      "Epoch: 074, Train Acc: 0.8133, Test Acc: 0.7632\n",
      "Epoch: 075, Train Acc: 0.8133, Test Acc: 0.7632\n",
      "Epoch: 076, Train Acc: 0.7933, Test Acc: 0.7895\n",
      "Epoch: 077, Train Acc: 0.7800, Test Acc: 0.7632\n",
      "Epoch: 078, Train Acc: 0.8000, Test Acc: 0.7895\n",
      "Epoch: 079, Train Acc: 0.8067, Test Acc: 0.7895\n",
      "Epoch: 080, Train Acc: 0.8133, Test Acc: 0.7895\n",
      "Epoch: 081, Train Acc: 0.8133, Test Acc: 0.7632\n",
      "Epoch: 082, Train Acc: 0.8200, Test Acc: 0.7632\n",
      "Epoch: 083, Train Acc: 0.8133, Test Acc: 0.7632\n",
      "Epoch: 084, Train Acc: 0.8267, Test Acc: 0.7632\n",
      "Epoch: 085, Train Acc: 0.8267, Test Acc: 0.7632\n",
      "Epoch: 086, Train Acc: 0.8333, Test Acc: 0.7632\n",
      "Epoch: 087, Train Acc: 0.8000, Test Acc: 0.7895\n",
      "Epoch: 088, Train Acc: 0.8333, Test Acc: 0.7632\n",
      "Epoch: 089, Train Acc: 0.8000, Test Acc: 0.7895\n",
      "Epoch: 090, Train Acc: 0.8000, Test Acc: 0.7895\n",
      "Epoch: 091, Train Acc: 0.8067, Test Acc: 0.7895\n",
      "Epoch: 092, Train Acc: 0.8067, Test Acc: 0.7895\n",
      "Epoch: 093, Train Acc: 0.8133, Test Acc: 0.7895\n",
      "Epoch: 094, Train Acc: 0.8333, Test Acc: 0.7895\n",
      "Epoch: 095, Train Acc: 0.8200, Test Acc: 0.7632\n",
      "Epoch: 096, Train Acc: 0.8333, Test Acc: 0.7632\n",
      "Epoch: 097, Train Acc: 0.8133, Test Acc: 0.7895\n",
      "Epoch: 098, Train Acc: 0.8200, Test Acc: 0.7895\n",
      "Epoch: 099, Train Acc: 0.8133, Test Acc: 0.7895\n",
      "Epoch: 100, Train Acc: 0.8000, Test Acc: 0.7895\n",
      "Epoch: 101, Train Acc: 0.8067, Test Acc: 0.7895\n",
      "Epoch: 102, Train Acc: 0.7867, Test Acc: 0.7632\n",
      "Epoch: 103, Train Acc: 0.7933, Test Acc: 0.7895\n",
      "Epoch: 104, Train Acc: 0.8067, Test Acc: 0.7895\n",
      "Epoch: 105, Train Acc: 0.8133, Test Acc: 0.7895\n",
      "Epoch: 106, Train Acc: 0.7867, Test Acc: 0.8158\n",
      "Epoch: 107, Train Acc: 0.7867, Test Acc: 0.7895\n",
      "Epoch: 108, Train Acc: 0.7867, Test Acc: 0.8158\n",
      "Epoch: 109, Train Acc: 0.8067, Test Acc: 0.8158\n",
      "Epoch: 110, Train Acc: 0.8200, Test Acc: 0.7632\n",
      "Epoch: 111, Train Acc: 0.8067, Test Acc: 0.7632\n",
      "Epoch: 112, Train Acc: 0.8400, Test Acc: 0.7632\n",
      "Epoch: 113, Train Acc: 0.8267, Test Acc: 0.7895\n",
      "Epoch: 114, Train Acc: 0.8133, Test Acc: 0.7895\n",
      "Epoch: 115, Train Acc: 0.8133, Test Acc: 0.7895\n",
      "Epoch: 116, Train Acc: 0.8333, Test Acc: 0.7632\n",
      "Epoch: 117, Train Acc: 0.8333, Test Acc: 0.7632\n",
      "Epoch: 118, Train Acc: 0.8400, Test Acc: 0.7632\n",
      "Epoch: 119, Train Acc: 0.8400, Test Acc: 0.7632\n",
      "Epoch: 120, Train Acc: 0.8267, Test Acc: 0.7632\n",
      "Epoch: 121, Train Acc: 0.8333, Test Acc: 0.7895\n",
      "Epoch: 122, Train Acc: 0.8267, Test Acc: 0.7632\n",
      "Epoch: 123, Train Acc: 0.8400, Test Acc: 0.7632\n",
      "Epoch: 124, Train Acc: 0.8400, Test Acc: 0.7632\n",
      "Epoch: 125, Train Acc: 0.8400, Test Acc: 0.7632\n",
      "Epoch: 126, Train Acc: 0.8200, Test Acc: 0.7895\n",
      "Epoch: 127, Train Acc: 0.8200, Test Acc: 0.7895\n",
      "Epoch: 128, Train Acc: 0.8133, Test Acc: 0.7895\n",
      "Epoch: 129, Train Acc: 0.8200, Test Acc: 0.7632\n",
      "Epoch: 130, Train Acc: 0.8333, Test Acc: 0.7895\n",
      "Epoch: 131, Train Acc: 0.8200, Test Acc: 0.7368\n",
      "Epoch: 132, Train Acc: 0.8333, Test Acc: 0.7632\n",
      "Epoch: 133, Train Acc: 0.8400, Test Acc: 0.7632\n",
      "Epoch: 134, Train Acc: 0.8400, Test Acc: 0.7632\n",
      "Epoch: 135, Train Acc: 0.8267, Test Acc: 0.7632\n",
      "Epoch: 136, Train Acc: 0.8400, Test Acc: 0.7632\n",
      "Epoch: 137, Train Acc: 0.8200, Test Acc: 0.7368\n",
      "Epoch: 138, Train Acc: 0.8200, Test Acc: 0.7895\n",
      "Epoch: 139, Train Acc: 0.8200, Test Acc: 0.7368\n",
      "Epoch: 140, Train Acc: 0.8400, Test Acc: 0.7632\n",
      "Epoch: 141, Train Acc: 0.8267, Test Acc: 0.7632\n",
      "Epoch: 142, Train Acc: 0.8200, Test Acc: 0.7368\n",
      "Epoch: 143, Train Acc: 0.8267, Test Acc: 0.7895\n",
      "Epoch: 144, Train Acc: 0.8400, Test Acc: 0.7632\n",
      "Epoch: 145, Train Acc: 0.8400, Test Acc: 0.7632\n",
      "Epoch: 146, Train Acc: 0.8067, Test Acc: 0.7632\n",
      "Epoch: 147, Train Acc: 0.8200, Test Acc: 0.7632\n",
      "Epoch: 148, Train Acc: 0.8200, Test Acc: 0.7895\n",
      "Epoch: 149, Train Acc: 0.8200, Test Acc: 0.7632\n",
      "Epoch: 150, Train Acc: 0.8133, Test Acc: 0.7632\n",
      "Epoch: 151, Train Acc: 0.8000, Test Acc: 0.7632\n",
      "Epoch: 152, Train Acc: 0.8200, Test Acc: 0.7632\n",
      "Epoch: 153, Train Acc: 0.8200, Test Acc: 0.7632\n",
      "Epoch: 154, Train Acc: 0.8267, Test Acc: 0.7632\n",
      "Epoch: 155, Train Acc: 0.8267, Test Acc: 0.7368\n",
      "Epoch: 156, Train Acc: 0.8267, Test Acc: 0.7368\n",
      "Epoch: 157, Train Acc: 0.8267, Test Acc: 0.7368\n",
      "Epoch: 158, Train Acc: 0.8267, Test Acc: 0.7632\n",
      "Epoch: 159, Train Acc: 0.8267, Test Acc: 0.7632\n",
      "Epoch: 160, Train Acc: 0.8267, Test Acc: 0.7632\n",
      "Epoch: 161, Train Acc: 0.8267, Test Acc: 0.7632\n",
      "Epoch: 162, Train Acc: 0.8200, Test Acc: 0.7632\n",
      "Epoch: 163, Train Acc: 0.8267, Test Acc: 0.7632\n",
      "Epoch: 164, Train Acc: 0.8267, Test Acc: 0.7632\n",
      "Epoch: 165, Train Acc: 0.8267, Test Acc: 0.7368\n",
      "Epoch: 166, Train Acc: 0.8267, Test Acc: 0.7368\n",
      "Epoch: 167, Train Acc: 0.8267, Test Acc: 0.7632\n",
      "Epoch: 168, Train Acc: 0.8267, Test Acc: 0.7632\n",
      "Epoch: 169, Train Acc: 0.8267, Test Acc: 0.7632\n",
      "Epoch: 170, Train Acc: 0.8200, Test Acc: 0.7632\n",
      "Epoch: 171, Train Acc: 0.8267, Test Acc: 0.7632\n",
      "Epoch: 172, Train Acc: 0.8200, Test Acc: 0.7632\n",
      "Epoch: 173, Train Acc: 0.8200, Test Acc: 0.7632\n",
      "Epoch: 174, Train Acc: 0.8200, Test Acc: 0.7632\n",
      "Epoch: 175, Train Acc: 0.8267, Test Acc: 0.7632\n",
      "Epoch: 176, Train Acc: 0.8267, Test Acc: 0.7632\n",
      "Epoch: 177, Train Acc: 0.8267, Test Acc: 0.7632\n",
      "Epoch: 178, Train Acc: 0.8267, Test Acc: 0.7632\n",
      "Epoch: 179, Train Acc: 0.8267, Test Acc: 0.7632\n",
      "Epoch: 180, Train Acc: 0.8133, Test Acc: 0.7105\n",
      "Epoch: 181, Train Acc: 0.8267, Test Acc: 0.7368\n",
      "Epoch: 182, Train Acc: 0.8267, Test Acc: 0.7632\n",
      "Epoch: 183, Train Acc: 0.8267, Test Acc: 0.7632\n",
      "Epoch: 184, Train Acc: 0.8267, Test Acc: 0.7368\n",
      "Epoch: 185, Train Acc: 0.8267, Test Acc: 0.7368\n",
      "Epoch: 186, Train Acc: 0.8267, Test Acc: 0.7632\n",
      "Epoch: 187, Train Acc: 0.8267, Test Acc: 0.7368\n",
      "Epoch: 188, Train Acc: 0.8267, Test Acc: 0.7632\n",
      "Epoch: 189, Train Acc: 0.8267, Test Acc: 0.7632\n",
      "Epoch: 190, Train Acc: 0.8267, Test Acc: 0.7632\n",
      "Epoch: 191, Train Acc: 0.8267, Test Acc: 0.7632\n",
      "Epoch: 192, Train Acc: 0.8267, Test Acc: 0.7632\n",
      "Epoch: 193, Train Acc: 0.8267, Test Acc: 0.7632\n",
      "Epoch: 194, Train Acc: 0.8267, Test Acc: 0.7368\n",
      "Epoch: 195, Train Acc: 0.8200, Test Acc: 0.7632\n",
      "Epoch: 196, Train Acc: 0.8200, Test Acc: 0.7632\n",
      "Epoch: 197, Train Acc: 0.8200, Test Acc: 0.7632\n",
      "Epoch: 198, Train Acc: 0.8267, Test Acc: 0.7368\n",
      "Epoch: 199, Train Acc: 0.8267, Test Acc: 0.7632\n",
      "Epoch: 200, Train Acc: 0.8267, Test Acc: 0.7632\n"
     ]
    }
   ],
   "source": [
    "gcn = GCN()\n",
    "\n",
    "# optimizer\n",
    "optimizer = torch.optim.Adam(gcn.parameters(), lr=0.01)\n",
    "\n",
    "# loss\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def train(train_loader):\n",
    "    gcn.train()\n",
    "    for data in train_loader:  # Iterate in batches over the training dataset.\n",
    "        \"\"\"\n",
    "        train the model for one epoch.\n",
    "        \"\"\"\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        y_hat = gcn(x=data.x, edge_index=data.edge_index, batch=data.batch)\n",
    "        loss = criterion(input=y_hat, target=data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "def test(loader):\n",
    "    gcn.eval()\n",
    "    correct = 0\n",
    "    for data in loader:  # Iterate in batches over the training/test dataset.\n",
    "        out = gcn(data.x, data.edge_index, data.batch)  \n",
    "        pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "        correct += int((pred == data.y).sum())  # Check against ground-truth labels.\n",
    "    return correct / len(loader.dataset)  # Derive ratio of correct predictions.\n",
    "\n",
    "\n",
    "for epoch in range(200):\n",
    "    train(train_loader)\n",
    "    train_acc = test(train_loader)\n",
    "    test_acc = test(test_loader)\n",
    "    print(f'Epoch: {epoch + 1:03d}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_acc = test(test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "852px",
    "left": "493px",
    "top": "256px",
    "width": "358.375px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
