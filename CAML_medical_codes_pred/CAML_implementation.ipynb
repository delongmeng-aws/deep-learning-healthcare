{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAML: an attentional convolutional network to predict medical codes from clinical text\n",
    "\n",
    "## Overview\n",
    "\n",
    "In this project, we will implement the Convolutional Attention for Multi-Label classification (CAML) model proposed by Mullenbach et al. in the paper \"[Explainable Prediction of Medical Codes from Clinical Text](https://www.aclweb.org/anthology/N18-1100/)\".\n",
    "\n",
    "Clinical notes are text documents that are created by clinicians for each patient encounter. They are typically accompanied by medical codes, which describe the diagnosis and treatment. Annotating these codes is labor intensive and error prone; furthermore, the connection between the codes and the text is not annotated, obscuring the reasons and details behind specific diagnoses and treatments. Thus, let us implement CAML, an attentional convolutional network to predict medical codes from clinical text.\n",
    "\n",
    "<img src='img/clinical notes.png'>\n",
    "\n",
    "Image courtsey: [link](https://www.aclweb.org/anthology/2020.acl-demos.33/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed\n",
    "seed = 24\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "\n",
    "# Define data path\n",
    "DATA_PATH = \"lib/data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "For this project, we will be using the Indiana University Chest X-Ray dataset. The goal is to predict diseases using chest x-ray reports.\n",
    "\n",
    "Navigate to the data folder `DATA_PATH`, there are several files:\n",
    "\n",
    "- `train_df.csv`, `test_df.csv`: these two files contains the data used for training and testing.\n",
    "    - `Report ID` refers to a unique chest x-ray report.\n",
    "    - `Text` refers to the clinical report text.\n",
    "    - `Label` refers to the diseases.\n",
    "- `vocab.csv`: this file contains the vocabularies used in the clinical text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_df.csv  train_df.csv  vocab.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls {DATA_PATH}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, the first chest x-ray report in `train_df.csv` has:\n",
    "- `Report ID`: 1\n",
    "- `Text`: the cardiac silhouette and mediastinum size are within normal limits . there is no pulmonary edema . there is no focal consolidation . there are no xxxx of a pleural effusion . there is no evidence of pneumothorax . normal chest xxxxx .\n",
    "- `Label`: [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "where label is a multi-hot vector representing the following diseases:\n",
    "```\n",
    "normal\n",
    "cardiomegaly\n",
    "scoliosis / degenerative\n",
    "fractures bone\n",
    "pleural effusion\n",
    "thickening\n",
    "pneumothorax\n",
    "hernia hiatal\n",
    "calcinosis\n",
    "emphysema / pulmonary emphysema\n",
    "pneumonia / infiltrate / consolidation\n",
    "pulmonary edema\n",
    "pulmonary atelectasis\n",
    "cicatrix\n",
    "opacity\n",
    "nodule / mass\n",
    "airspace disease\n",
    "hypoinflation / hyperdistention\n",
    "catheters indwelling / surgical instruments / tube inserted / medical device\n",
    "other\n",
    "```\n",
    "\n",
    "So this report 1 is labeled as \"normal\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Prepare the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Helper Functions\n",
    "\n",
    "To begin, let us first implement some helper functions we will use later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_index(sequence, token2idx):\n",
    "    \"\"\"\n",
    "    Convert the sequnce of tokens to indices. If the word in unknown, then map it to '<unk>'.\n",
    "    \n",
    "    INPUT:\n",
    "        sequence (type: list of str): a sequence of tokens\n",
    "        token2idx (type: dict): a dictionary mapping token to the corresponding index\n",
    "    \n",
    "    OUTPUT:\n",
    "        indices (type: list of int): a sequence of indicies\n",
    "        \n",
    "    EXAMPLE:\n",
    "        >>> sequence = ['hello', 'world', 'unknown_word']\n",
    "        >>> token2idx = {'hello': 0, 'world': 1, '<unk>': 2}\n",
    "        >>> to_index(sequence, token2idx)\n",
    "        [0, 1, 2]\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    for word in sequence:\n",
    "        if word in token2idx.keys():\n",
    "            result.append(token2idx[word])\n",
    "        else:\n",
    "            result.append(token2idx['<unk>'])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 CustomDataset\n",
    "\n",
    "Now, let us implement a custom dataset using PyTorch class `Dataset`, which will characterize the key features of the dataset we want to generate.\n",
    "\n",
    "We will use the clinical text as input and medical codes as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "NUM_WORDS = 1253\n",
    "NUM_CLASSES = 20\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, filename):       \n",
    "        \n",
    "        # read in the data files\n",
    "        self.data = pd.read_csv(filename)\n",
    "        \n",
    "        # load word lookup\n",
    "        self.idx2word, self.word2idx = self.load_lookup(f'{DATA_PATH}/vocab.csv', padding=True)\n",
    "        \n",
    "        assert len(self.idx2word) == len(self.word2idx) == NUM_WORDS\n",
    "        \n",
    "    def load_lookup(self, filename, padding=False):\n",
    "        \"\"\" load lookup for word \"\"\"\n",
    "        idx2token = {}\n",
    "        with open(filename, 'r') as f:\n",
    "            for i, line in enumerate(f):\n",
    "                line = line.strip()\n",
    "                idx2token[i] = line\n",
    "        token2idx = {w:i for i,w in idx2token.items()}\n",
    "        return idx2token, token2idx\n",
    "        \n",
    "    def __len__(self):\n",
    "        \n",
    "        \"\"\"\n",
    "        Return the number of samples (i.e. admissions).\n",
    "        \"\"\"\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        \"\"\"\n",
    "        Generate one sample of data.\n",
    "        \"\"\"\n",
    "        data = self.data.iloc[index]\n",
    "        text = data['Text'].split(' ')\n",
    "        label = data['Label']\n",
    "        # convert label string to list\n",
    "        label = [int(l) for l in label.strip('[]').split(', ')]\n",
    "        assert len(label) == NUM_CLASSES\n",
    "        text = to_index(text, self.word2idx)\n",
    "        return torch.tensor(text, dtype=torch.long), torch.tensor(label, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Collate Function\n",
    "\n",
    "The collate function `collate_fn()` will be called by `DataLoader` after fetching a list of samples using the indices from `CustomDataset` to collate the list of samples into batches.\n",
    "\n",
    "For example, assume the `DataLoader` gets a list of two samples.\n",
    "\n",
    "```\n",
    "[ [3,  1,  2, 8, 5], \n",
    "  [12, 13, 6, 7, 12, 23, 11] ]\n",
    "```\n",
    "\n",
    "where the first sample has text `[3, 1, 2, 8, 5]` the second sample has text `[12, 13, 6, 7, 12, 23, 11]`.\n",
    "\n",
    "The collate function `collate_fn()` is supposed to pad them into the same shape (7), where 7 is the maximum number of tokens.\n",
    "\n",
    "```\n",
    "[ [3,  1,  2, 8, 5, *0*, *0*], \n",
    "  [12, 13, 6, 7, 12, 23,  11 ]\n",
    "```\n",
    "\n",
    "where `*0*` indicates the padding token.\n",
    "\n",
    "We need to pad the sequences into the same length so that we can do batch training on GPU. And we also need this mask so that when training, we can ignored the padded value as they actually do not contain any information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def collate_fn(data):\n",
    "    \"\"\"\n",
    "    OUTPUT:\n",
    "        text: the padded text, shape: (batch size, max length)\n",
    "        labels: the stacked labels, shape: (batch size, num classes)\n",
    "    \"\"\"\n",
    "    text, labels = zip(*data)\n",
    "\n",
    "    # pad the text using pad_sequence()\n",
    "    text = pad_sequence(text, batch_first=True)\n",
    "    \n",
    "    # stack the labels\n",
    "    labels = torch.stack(labels)\n",
    "    \n",
    "    return text, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataset = CustomDataset(f'{DATA_PATH}/train_df.csv')\n",
    "loader = DataLoader(dataset, batch_size=10, collate_fn=collate_fn)\n",
    "loader_iter = iter(loader)\n",
    "text, labels = next(loader_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All done, now let us load the dataset and data loader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = CustomDataset(f'{DATA_PATH}/train_df.csv')\n",
    "test_set = CustomDataset(f'{DATA_PATH}/test_df.csv')\n",
    "train_loader = DataLoader(train_set, batch_size=32, collate_fn=collate_fn, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=32, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_iter = iter(train_loader)\n",
    "text, labels = next(train_loader_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[681, 676,  46,  ...,   0,   0,   0],\n",
       "        [ 55,   9,   7,  ...,   0,   0,   0],\n",
       "        [  4,  31,   6,  ...,   0,   0,   0],\n",
       "        ...,\n",
       "        [ 46, 185,  10,  ...,   0,   0,   0],\n",
       "        [  4,  34, 447,  ...,   0,   0,   0],\n",
       "        [  4,  34,  10,  ...,   0,   0,   0]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 129])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "         0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
       "         0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "         0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
       "         0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         1., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1.,\n",
       "         0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "         0., 0.],\n",
       "        [0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1.,\n",
       "         1., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.],\n",
       "        [0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "         0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "         0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "         0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "         0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "         0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 20])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Model\n",
    "\n",
    "Next, we will implement the CAML model.\n",
    "\n",
    "<img src='img/caml.png'>\n",
    "\n",
    "CAML is a convolutional neural network (CNN)-based model. It employs a per-label attention mechanism, which allows the model to learn distinct document representations for each label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_size=10\n",
    "num_filter_maps=16\n",
    "embed_size=100\n",
    "dropout=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 4.6424e-02, -5.8118e-03, -1.1895e-01,  1.1350e-01,  1.1773e-01,\n",
       "         -1.2843e-01, -3.2863e-01, -2.8696e-01, -1.9685e-01,  3.0065e-01,\n",
       "          1.9048e-01,  4.0555e-01,  4.0449e-02,  1.2111e-01, -3.0619e-01,\n",
       "          3.7543e-01],\n",
       "        [-1.4240e-01,  3.8347e-01,  1.5925e-01, -1.6462e-01,  3.8513e-01,\n",
       "          3.9925e-02, -4.0551e-01, -3.5628e-01,  9.6371e-02, -9.1424e-02,\n",
       "         -2.7839e-01,  2.3444e-01, -1.6602e-02,  1.3793e-01, -3.8036e-01,\n",
       "         -1.1662e-01],\n",
       "        [ 2.9073e-01,  2.4191e-01,  2.7346e-02, -1.3438e-01,  3.6025e-01,\n",
       "         -1.6374e-01,  1.3985e-02,  3.6275e-01,  3.6183e-01,  1.8094e-02,\n",
       "          2.7703e-01, -8.2314e-02, -2.9007e-02,  6.2736e-02, -2.4469e-01,\n",
       "         -2.9445e-01],\n",
       "        [ 2.7320e-01,  2.2017e-01,  1.4782e-01, -3.4094e-01, -3.6820e-01,\n",
       "          1.3770e-01,  2.0380e-01,  3.2225e-01, -2.5532e-01, -1.3278e-01,\n",
       "          3.5933e-01, -3.8846e-01, -2.1118e-01,  3.4978e-01, -2.4956e-01,\n",
       "         -4.5794e-02],\n",
       "        [-4.0500e-01,  2.7919e-01, -2.2020e-01,  1.1968e-01, -2.4397e-01,\n",
       "         -3.0390e-01, -4.0707e-01,  3.5123e-01,  4.3634e-02, -5.0078e-02,\n",
       "          6.2067e-02,  2.5546e-01,  2.5391e-01,  3.2784e-01,  4.5019e-03,\n",
       "          5.9216e-02],\n",
       "        [ 2.9056e-01, -2.5657e-01, -2.1867e-01, -1.7784e-02,  2.5055e-01,\n",
       "          3.0287e-01, -2.6360e-01, -3.6705e-01, -3.2142e-01, -1.3798e-01,\n",
       "          4.0499e-01,  5.9069e-02,  2.1972e-01, -1.3374e-01, -2.8356e-01,\n",
       "          2.6671e-01],\n",
       "        [-2.5072e-01,  3.6090e-01, -8.9493e-02, -1.8538e-01, -1.3374e-01,\n",
       "         -2.8662e-01, -2.4269e-02,  1.3940e-01, -3.9173e-01,  1.0292e-02,\n",
       "         -1.3376e-01,  3.1265e-01,  2.6309e-01, -8.0403e-03,  9.8182e-02,\n",
       "         -1.3245e-01],\n",
       "        [ 1.0376e-02,  3.3244e-01, -3.5463e-01,  2.4763e-01,  5.3557e-03,\n",
       "         -2.1008e-01, -2.2589e-02, -2.3729e-01, -6.7651e-02,  2.8821e-01,\n",
       "         -1.3611e-01,  3.9570e-01,  1.8543e-01,  3.8249e-01,  6.5656e-02,\n",
       "          9.5503e-02],\n",
       "        [-3.3926e-02, -8.0375e-02,  7.6322e-02, -8.2902e-03, -2.2618e-01,\n",
       "          6.6631e-02, -3.8627e-01,  3.8529e-01, -2.8037e-01,  4.0199e-01,\n",
       "          1.4261e-01,  6.4257e-02, -3.5995e-01, -3.9135e-01, -1.3829e-01,\n",
       "         -1.9256e-01],\n",
       "        [-3.9688e-01, -1.8472e-01, -1.2099e-01, -2.9640e-01,  1.9149e-01,\n",
       "         -2.3404e-01, -2.4086e-01,  4.6046e-02,  2.4906e-01,  1.2248e-01,\n",
       "          9.7632e-02,  2.4372e-01,  3.8159e-01,  3.1124e-01,  1.0091e-02,\n",
       "          1.6805e-01],\n",
       "        [-3.1770e-01, -2.5665e-01,  3.9336e-01,  2.8950e-01,  2.0982e-01,\n",
       "          2.5303e-01,  3.0542e-01, -3.9255e-01, -3.3441e-01, -8.1086e-02,\n",
       "         -2.5106e-02,  4.0150e-01,  1.9383e-01, -2.6165e-01, -2.6052e-01,\n",
       "         -3.7639e-01],\n",
       "        [ 1.9543e-01, -7.5152e-02,  4.0024e-01,  2.6716e-02,  2.7911e-01,\n",
       "         -3.3580e-04,  9.0376e-02, -3.8176e-01,  3.0454e-01,  2.8644e-01,\n",
       "         -1.0501e-03,  3.7020e-01, -3.1096e-01,  3.7754e-01, -1.1160e-01,\n",
       "         -1.3477e-01],\n",
       "        [-3.1250e-01, -3.7956e-01, -4.0677e-01,  3.4444e-01,  2.7688e-01,\n",
       "          2.2802e-01, -8.3567e-02,  3.9819e-01,  1.6360e-01,  7.7394e-02,\n",
       "          3.1994e-01, -2.4863e-01, -2.4572e-01,  1.9127e-01, -2.2978e-01,\n",
       "          3.4659e-01],\n",
       "        [ 5.5463e-02, -2.3385e-01,  3.6349e-01,  3.7165e-01,  1.6715e-01,\n",
       "         -3.2682e-01, -3.6501e-01,  1.3273e-01,  1.5551e-01,  1.3445e-01,\n",
       "         -3.2239e-01,  3.5525e-02,  3.8061e-01,  1.9754e-01,  7.6735e-02,\n",
       "         -8.4943e-02],\n",
       "        [ 2.5289e-02, -1.3782e-01,  6.3635e-02, -8.6620e-02,  2.5656e-01,\n",
       "          1.6304e-01,  1.3018e-01, -3.8387e-01,  3.0338e-01,  2.1253e-01,\n",
       "          2.5949e-02, -1.3723e-01, -5.5664e-02,  1.5087e-01,  1.0512e-01,\n",
       "          3.6415e-01],\n",
       "        [-6.1994e-02, -3.7938e-01,  3.9974e-01, -1.5280e-01, -3.4136e-01,\n",
       "         -2.1311e-02, -2.7142e-01, -6.9754e-02, -1.1318e-01, -2.5200e-01,\n",
       "         -1.2443e-01, -1.3162e-01,  9.4122e-04, -1.4701e-01, -3.8671e-01,\n",
       "         -1.6016e-01],\n",
       "        [-3.0334e-01,  4.3435e-02,  1.8008e-01, -2.9927e-02,  1.1561e-01,\n",
       "          1.4099e-01, -8.7022e-03, -3.8807e-01,  5.4512e-02,  3.0240e-03,\n",
       "          3.3956e-01, -3.8922e-01,  2.0768e-01,  3.0914e-01, -1.6531e-01,\n",
       "          3.5724e-01],\n",
       "        [-2.3239e-01,  3.5141e-01, -3.7659e-01,  4.5341e-02, -3.8979e-01,\n",
       "         -9.4018e-02, -2.1107e-01, -1.0708e-01, -1.0572e-01,  1.1541e-01,\n",
       "         -2.3577e-01,  2.3947e-01, -2.3972e-01, -2.4993e-01,  2.0823e-01,\n",
       "          7.1391e-02],\n",
       "        [-2.2004e-01,  1.4716e-01, -4.0088e-01,  3.0850e-01, -3.8076e-01,\n",
       "          1.3198e-01,  1.0313e-01,  4.9437e-02,  9.0858e-02, -3.1810e-01,\n",
       "         -3.8898e-01,  2.2887e-01,  4.0467e-01, -2.1195e-01,  3.6269e-01,\n",
       "         -9.2323e-02],\n",
       "        [ 3.5686e-01,  3.9890e-01,  9.8902e-02, -1.8488e-01,  2.2741e-01,\n",
       "         -1.4326e-02,  2.2976e-02,  7.5803e-02, -3.6687e-01, -1.8423e-01,\n",
       "          1.9953e-01,  5.4944e-03, -2.4832e-01,  1.8568e-01, -2.3442e-01,\n",
       "          1.6032e-01]], requires_grad=True)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import floor\n",
    "from torch.nn.init import xavier_uniform_\n",
    "\n",
    "# embedding layer\n",
    "embed = nn.Embedding(NUM_WORDS, embed_size, padding_idx=0)\n",
    "embed_drop = nn.Dropout(p=dropout)\n",
    "\n",
    "# initialize conv layer as in section 2.1\n",
    "conv = nn.Conv1d(embed_size, num_filter_maps, kernel_size=kernel_size, padding=int(floor(kernel_size/2)))\n",
    "xavier_uniform_(conv.weight)\n",
    "\n",
    "# context vectors for computing attention as in section 2.2\n",
    "U = nn.Linear(num_filter_maps, 20)\n",
    "xavier_uniform_(U.weight)\n",
    "\n",
    "# final layer: create a matrix to use for the NUM_CLASSES binary classifiers as in section 2.3\n",
    "final = nn.Linear(num_filter_maps, NUM_CLASSES)\n",
    "xavier_uniform_(final.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step by step, we can monitor how the shape changes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 129])\n",
      "torch.Size([32, 129, 100])\n",
      "torch.Size([32, 129, 100])\n"
     ]
    }
   ],
   "source": [
    "print(text.shape)\n",
    "text = embed(text)\n",
    "print(text.shape)\n",
    "text = embed_drop(text)\n",
    "print(text.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 129, 100])\n",
      "torch.Size([32, 100, 129])\n",
      "torch.Size([32, 16, 130])\n",
      "torch.Size([32, 16, 130])\n"
     ]
    }
   ],
   "source": [
    "print(text.shape)\n",
    "text = text.transpose(1, 2)\n",
    "print(text.shape)\n",
    "text = conv(text)\n",
    "print(text.shape)\n",
    "text = torch.tanh(text)\n",
    "print(text.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 130, 16])\n"
     ]
    }
   ],
   "source": [
    "text = text.transpose(1,2)\n",
    "print(text.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 16, 130])\n",
      "torch.Size([20, 16])\n"
     ]
    }
   ],
   "source": [
    "temp = text.transpose(1,2)\n",
    "print(temp.shape)\n",
    "print(U.weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 20, 130])\n"
     ]
    }
   ],
   "source": [
    "alpha = torch.matmul(U.weight, temp)\n",
    "print(alpha.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 20, 130])\n"
     ]
    }
   ],
   "source": [
    "alpha = F.softmax(alpha, dim=2)\n",
    "print(alpha.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 20, 16])\n"
     ]
    }
   ],
   "source": [
    "v = torch.matmul(alpha, text)\n",
    "print(v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 16])\n"
     ]
    }
   ],
   "source": [
    "print((final.weight).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 20, 16])\n"
     ]
    }
   ],
   "source": [
    "print((final.weight.unsqueeze(0)).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 20, 16])\n",
      "torch.Size([32, 20])\n",
      "torch.Size([32, 20])\n",
      "torch.Size([32, 20])\n"
     ]
    }
   ],
   "source": [
    "temp = final.weight*v\n",
    "print(temp.shape)\n",
    "temp = torch.sum(temp, dim=2)\n",
    "print(temp.shape)\n",
    "temp = temp + final.bias\n",
    "print(temp.shape)\n",
    "y_hat = torch.sigmoid(temp)\n",
    "print(y_hat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's put together the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import floor\n",
    "from torch.nn.init import xavier_uniform_\n",
    "\n",
    "class CAML(nn.Module):\n",
    "\n",
    "    def __init__(self, kernel_size=10, num_filter_maps=16, embed_size=100, dropout=0.5):\n",
    "        super(CAML, self).__init__()\n",
    "        \n",
    "        # embedding layer\n",
    "        self.embed = nn.Embedding(NUM_WORDS, embed_size, padding_idx=0)\n",
    "        self.embed_drop = nn.Dropout(p=dropout)\n",
    "\n",
    "        # initialize conv layer as in section 2.1\n",
    "        self.conv = nn.Conv1d(embed_size, num_filter_maps, kernel_size=kernel_size, padding=int(floor(kernel_size/2)))\n",
    "        xavier_uniform_(self.conv.weight)\n",
    "\n",
    "        # context vectors for computing attention as in section 2.2\n",
    "        self.U = nn.Linear(num_filter_maps, 20)\n",
    "        xavier_uniform_(self.U.weight)\n",
    "\n",
    "        # final layer: create a matrix to use for the NUM_CLASSES binary classifiers as in section 2.3\n",
    "        self.final = nn.Linear(num_filter_maps, NUM_CLASSES)\n",
    "        xavier_uniform_(self.final.weight)\n",
    "        \n",
    "    def forward_embed(self, text):\n",
    "        \"\"\"\n",
    "        Feed text through the embedding (self.embed) and dropout layer (self.embed_drop).\n",
    "        \n",
    "        INPUT: \n",
    "            text: (batch size, seq_len)\n",
    "            \n",
    "        OURPUT:\n",
    "            text: (batch size, seq_len, embed_size)\n",
    "        \"\"\"\n",
    "        text = self.embed(text)\n",
    "        text = self.embed_drop(text)\n",
    "        return text\n",
    "        \n",
    "    def forward_conv(self, text):\n",
    "        \"\"\"\n",
    "        Feed text through the convolution layer (self.conv) and tanh activation function (torch.tanh) \n",
    "        in eq (1) in the paper.\n",
    "        \n",
    "        INTPUT:\n",
    "            text: (batch size, embed_size, seq_len)\n",
    "            \n",
    "        OUTPUT:\n",
    "            text: (batch size, num_filter_maps, seq_len)\n",
    "        \"\"\"\n",
    "        text = self.conv(text)\n",
    "        text = torch.tanh(text)\n",
    "        return text\n",
    "        \n",
    "    def forward_calc_atten(self, text):\n",
    "        \"\"\"\n",
    "        Calculate the attention weights in eq (2) in the paper. \n",
    "        \n",
    "        INPUT:\n",
    "            text: (batch size, seq_len, num_filter_maps)\n",
    "\n",
    "        OUTPUT:\n",
    "            alpha: (batch size, num_class, seq_len), the attention weights\n",
    "        \"\"\"\n",
    "        # (batch size, seq_len, num_filter_maps) -> (batch size, num_filter_mapsseq_len)\n",
    "        text = text.transpose(1,2)\n",
    "        alpha = torch.matmul(self.U.weight, text)\n",
    "        alpha = F.softmax(alpha, dim=2)\n",
    "        return alpha\n",
    "        \n",
    "    def forward_aply_atten(self, alpha, text):\n",
    "        \"\"\"\n",
    "        Apply the attention in eq (3) in the paper.\n",
    "\n",
    "        INPUT: \n",
    "            text: (batch size, seq_len, num_filter_maps)\n",
    "            alpha: (batch size, num_class, seq_len), the attention weights\n",
    "            \n",
    "        OUTPUT:\n",
    "            v: (batch size, num_class, num_filter_maps), vector representations for each label\n",
    "        \"\"\"\n",
    "        v = torch.matmul(alpha, text)\n",
    "        return v\n",
    "    \n",
    "    def forward_linear(self, v):\n",
    "        \"\"\"\n",
    "        Apply the final linear classification in eq (5) in the paper.\n",
    "        \n",
    "        INPUT: \n",
    "            v: (batch size, num_class, num_filter_maps), vector representations for each label\n",
    "            \n",
    "        OUTPUT:\n",
    "            y_hat: (batch size, num_class), label probability\n",
    "        \"\"\"\n",
    "        # multiply `self.final.weight` v `text` element-wise using torch.mul()\n",
    "        temp = self.final.weight*v\n",
    "        # sum the result over dim 2 (i.e. num_filter_maps)\n",
    "        temp = torch.sum(temp, dim=2)\n",
    "        # add the result with `self.final.bias`\n",
    "        temp = temp + self.final.bias\n",
    "        # apply sigmoid with torch.sigmoid()\n",
    "        y_hat = torch.sigmoid(temp)\n",
    "        return y_hat\n",
    "\n",
    "        \n",
    "    def forward(self, text):\n",
    "        # 1. get embeddings and apply dropout\n",
    "        text = self.forward_embed(text)\n",
    "        # (batch size, seq_len, embed_size) -> (batch size, embed_size, seq_len);\n",
    "        text = text.transpose(1, 2)\n",
    "\n",
    "        # 2. apply convolution and nonlinearity (tanh)\n",
    "        text = self.forward_conv(text)\n",
    "        # (batch size, num_filter_maps, seq_len) -> (batch size, seq_len, num_filter_maps);\n",
    "        text = text.transpose(1,2)\n",
    "        \n",
    "        # 3. calculate attention\n",
    "        alpha = self.forward_calc_atten(text)\n",
    "        \n",
    "        # 3. apply attention\n",
    "        v = self.forward_aply_atten(alpha, text)\n",
    "           \n",
    "        # 4. final layer classification\n",
    "        y_hat = self.forward_linear(v)\n",
    "        \n",
    "        return y_hat\n",
    "    \n",
    "    \n",
    "model = CAML()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CAML(\n",
       "  (embed): Embedding(1253, 100, padding_idx=0)\n",
       "  (embed_drop): Dropout(p=0.5, inplace=False)\n",
       "  (conv): Conv1d(100, 16, kernel_size=(10,), stride=(1,), padding=(5,))\n",
       "  (U): Linear(in_features=16, out_features=20, bias=True)\n",
       "  (final): Linear(in_features=16, out_features=20, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CAML()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Training and Inferencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CAML()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us implement the `eval()` and `train()` function. Note that `train()` should call `eval()` at the end of each training epoch to see the results on the validaion dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "def eval(model, test_loader):\n",
    "    \n",
    "    \"\"\"    \n",
    "    INPUT:\n",
    "        model: the CAML model\n",
    "        test_loader: dataloader\n",
    "        \n",
    "    OUTPUT:\n",
    "        precision: overall micro precision score\n",
    "        recall: overall micro recall score\n",
    "        f1: overall micro f1 score\n",
    "    \"\"\"\n",
    "\n",
    "    model.eval()\n",
    "    y_pred = torch.LongTensor()\n",
    "    y_true = torch.LongTensor()\n",
    "    model.eval()\n",
    "    for sequences, labels in test_loader:\n",
    "        y_hat = model(sequences)\n",
    "        y_hat = y_hat > 0.5\n",
    "        y_pred = torch.cat((y_pred,  y_hat.detach().to('cpu')), dim=0)\n",
    "        y_true = torch.cat((y_true, labels.detach().to('cpu')), dim=0)\n",
    "    \n",
    "    p, r, f, _ = precision_recall_fscore_support(y_true, y_pred, average='micro')\n",
    "    return p, r, f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \t Training Loss: 0.456818\n",
      "Epoch: 1 \t Validation p: 0.00, r:0.00, f: 0.00\n",
      "Epoch: 2 \t Training Loss: 0.261946\n",
      "Epoch: 2 \t Validation p: 1.00, r:0.00, f: 0.00\n",
      "Epoch: 3 \t Training Loss: 0.227357\n",
      "Epoch: 3 \t Validation p: 0.88, r:0.13, f: 0.22\n",
      "Epoch: 4 \t Training Loss: 0.213753\n",
      "Epoch: 4 \t Validation p: 0.85, r:0.21, f: 0.34\n",
      "Epoch: 5 \t Training Loss: 0.201032\n",
      "Epoch: 5 \t Validation p: 0.84, r:0.23, f: 0.36\n",
      "Epoch: 6 \t Training Loss: 0.190393\n",
      "Epoch: 6 \t Validation p: 0.88, r:0.24, f: 0.38\n",
      "Epoch: 7 \t Training Loss: 0.178920\n",
      "Epoch: 7 \t Validation p: 0.90, r:0.34, f: 0.49\n",
      "Epoch: 8 \t Training Loss: 0.168405\n",
      "Epoch: 8 \t Validation p: 0.89, r:0.36, f: 0.52\n",
      "Epoch: 9 \t Training Loss: 0.160167\n",
      "Epoch: 9 \t Validation p: 0.90, r:0.39, f: 0.55\n",
      "Epoch: 10 \t Training Loss: 0.153547\n",
      "Epoch: 10 \t Validation p: 0.90, r:0.41, f: 0.56\n",
      "Epoch: 11 \t Training Loss: 0.147389\n",
      "Epoch: 11 \t Validation p: 0.90, r:0.43, f: 0.59\n",
      "Epoch: 12 \t Training Loss: 0.142694\n",
      "Epoch: 12 \t Validation p: 0.91, r:0.45, f: 0.60\n",
      "Epoch: 13 \t Training Loss: 0.137754\n",
      "Epoch: 13 \t Validation p: 0.91, r:0.49, f: 0.64\n",
      "Epoch: 14 \t Training Loss: 0.131401\n",
      "Epoch: 14 \t Validation p: 0.91, r:0.51, f: 0.65\n",
      "Epoch: 15 \t Training Loss: 0.127560\n",
      "Epoch: 15 \t Validation p: 0.92, r:0.53, f: 0.67\n",
      "Epoch: 16 \t Training Loss: 0.125191\n",
      "Epoch: 16 \t Validation p: 0.92, r:0.55, f: 0.68\n",
      "Epoch: 17 \t Training Loss: 0.120421\n",
      "Epoch: 17 \t Validation p: 0.91, r:0.56, f: 0.69\n",
      "Epoch: 18 \t Training Loss: 0.116409\n",
      "Epoch: 18 \t Validation p: 0.91, r:0.57, f: 0.70\n",
      "Epoch: 19 \t Training Loss: 0.113224\n",
      "Epoch: 19 \t Validation p: 0.91, r:0.59, f: 0.71\n",
      "Epoch: 20 \t Training Loss: 0.111325\n",
      "Epoch: 20 \t Validation p: 0.91, r:0.59, f: 0.72\n"
     ]
    }
   ],
   "source": [
    "def train(model, train_loader, test_loader, n_epochs):\n",
    "    \"\"\"    \n",
    "    INPUT:\n",
    "        model: the CAML model\n",
    "        train_loader: dataloder\n",
    "        val_loader: dataloader\n",
    "        n_epochs: total number of epochs\n",
    "    \"\"\"\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for sequences, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            y_hat = model(sequences)\n",
    "            loss = criterion(y_hat, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            \n",
    "        train_loss = train_loss / len(train_loader)\n",
    "        print('Epoch: {} \\t Training Loss: {:.6f}'.format(epoch+1, train_loss))\n",
    "        \n",
    "        p, r, f = eval(model, test_loader)\n",
    "        print('Epoch: {} \\t Validation p: {:.2f}, r:{:.2f}, f: {:.2f}'.format(epoch+1, p, r, f))\n",
    "\n",
    "    \n",
    "# number of epochs to train the model\n",
    "n_epochs = 20\n",
    "\n",
    "train(model, train_loader, test_loader, n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "p, r, f = eval(model, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
